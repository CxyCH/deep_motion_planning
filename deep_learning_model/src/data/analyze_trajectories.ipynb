{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.palettes import Spectral6\n",
    "output_notebook()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some stats about each trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = '../../data/raw'\n",
    "base_dir = os.path.join(data_dir, 'sample')\n",
    "envs = os.listdir(base_dir)\n",
    "envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(columns=['environment', 'path', 'trajectory', 'samples', 'duration', \n",
    "                              'linear_mean', 'linear_min' , 'linear_max', 'linear_std', 'linear_integral',\n",
    "                              'angular_mean', 'angular_min' , 'angular_max', 'angular_std', 'angular_integral', \n",
    "                              'target_distance', 'target_distance_mean', 'target_distance_min', 'target_distance_max' ])\n",
    "\n",
    "i = 0\n",
    "\n",
    "for e in envs:\n",
    "    \n",
    "    path = os.path.join(base_dir,e)\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    \n",
    "    for t in files:\n",
    "\n",
    "        df = pd.read_csv(t)\n",
    "        current = df[['stamp', 'target_x', 'target_y', 'linear_x', 'angular_z']].describe()\n",
    "\n",
    "        duration = (df.stamp.iloc[-1] - df.stamp.iloc[0]) * 1e-9\n",
    "        \n",
    "        distance_to_target = np.linalg.norm(df[['target_x', 'target_y']].values, axis=1)\n",
    "        \n",
    "        sample_period = (df.stamp.shift(-1) - df.stamp).fillna(method='ffill') * 1e-9\n",
    "        \n",
    "        stats.loc[i] = [e, t, \n",
    "                        os.path.basename(t).split('.')[0].split('_')[-1], \n",
    "                        current.stamp.loc['count'], \n",
    "                        duration,\n",
    "                        current.linear_x.loc['mean'],\n",
    "                        current.linear_x.loc['min'],\n",
    "                        current.linear_x.loc['max'],\n",
    "                        current.linear_x.loc['std'],\n",
    "                        (df['linear_x'] * sample_period).sum(),\n",
    "                        current.angular_z.loc['mean'],\n",
    "                        current.angular_z.loc['min'],\n",
    "                        current.angular_z.loc['max'],\n",
    "                        current.angular_z.loc['std'],\n",
    "                        (df['angular_z'] * sample_period).sum(),\n",
    "                        distance_to_target[0],\n",
    "                        np.mean(distance_to_target),\n",
    "                        np.min(distance_to_target),\n",
    "                        np.max(distance_to_target)]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.to_csv('stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read already created stats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = pd.read_csv(os.path.join(data_dir, 'stats.csv'), index_col=0)\n",
    "print(stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Histogram\n",
    "\n",
    "h = Histogram(stats, values='samples', color='environment')\n",
    "show(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the longest trajectories and compute a view stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "long = stats.loc[(stats['samples'] < 1500) & (stats['samples'] > 1000)].sort_values('samples')\n",
    "long = stats.loc[(stats['samples'] > 1000)].sort_values('samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of trajectories included after the long filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "long.groupby('environment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of samples included after the long filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "long.groupby('environment').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of the included environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "envs = long['environment'].unique()\n",
    "print(envs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the filtered files into a .txt file. Each line contains the path to one trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env = envs[1]\n",
    "paths = long.loc[long['environment'] == env]['path'].values\n",
    "\n",
    "with open(os.path.join(data_dir, 'paths.txt'), 'w') as f:\n",
    "    for p in paths:\n",
    "        f.write(p + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Further analysis of trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove trajectories with NAN values or trajectories with less than 10 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats_clean = stats.dropna().loc[stats['samples'] > 10]\n",
    "print(stats_clean.shape)\n",
    "stats_clean.sort_values('samples').head()\n",
    "\n",
    "long = stats_clean.loc[(stats_clean['samples'] > 1000)].sort_values('samples')\n",
    "short = stats_clean.loc[(stats_clean['samples'] < 1000)].sort_values('samples')\n",
    "long.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a PCA to visualize the data in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = short.loc[:,'linear_mean':'target_distance_max'].values\n",
    "print(X.shape)\n",
    "\n",
    "pca_dec = PCA(n_components=2)\n",
    "pca_dec.fit(X)\n",
    "Xpca = pca_dec.transform(X)\n",
    "print(Xpca.shape)\n",
    "\n",
    "#Xpca_long = pca_dec.transform(long.loc[:,'linear_mean':'target_distance_max'].values)\n",
    "#print(Xpca_long.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = figure(plot_height=800, plot_width=800)\n",
    "p.circle(Xpca[:,0], Xpca[:,1], radius=short['samples']*1e-3)\n",
    "#p.circle(Xpca_long[:,0], Xpca_long[:,1], color='firebrick', radius=long['samples']*1e-3)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"index\", \"$index\"),\n",
    "            (\"(x,y)\", \"($x, $y)\"),\n",
    "            (\"samples\", \"@samples\"),\n",
    "            (\"id\", \"@id\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "plot_data = ColumnDataSource(data=dict(x=Xpca[:,0], y=Xpca[:,1], samples=short['samples'], id=short['trajectory']))\n",
    "\n",
    "p1 = figure(plot_height=800, plot_width=800)\n",
    "p1.circle('x', 'y', source=plot_data, radius=2, alpha=0.75)\n",
    "p1.add_tools(hover)\n",
    "\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter trajectories with X > 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "short.iloc[Xpca[:,0] > 40].sort_values('trajectory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the list of files into a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths = short.iloc[Xpca[:,0] > 40]['path'].values\n",
    "with open(os.path.join(data_dir, 'paths.txt'), 'w') as f:\n",
    "    for p in paths:\n",
    "        f.write(p + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of trajecories to include after the PCA filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_include = Xpca[:,0] <= 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot found trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(data_dir, 'sample')\n",
    "envs = os.listdir(base_dir)\n",
    "envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = dict()\n",
    "\n",
    "count = 0\n",
    "for f in envs:\n",
    "    path = os.path.join(base_dir, f)\n",
    "    files[f] = [os.path.join(path,x) for x in os.listdir(path)]\n",
    "    count += len(files[f])\n",
    "print('We have found {} files'.format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 10 trajecories, specified by the environment variable and r in the script bellow. Each row in the grid represents one trajectory. The left plot shows the linear control commands and the distance to the goal pose. The right plot depicts the angular control commmands and the angle to the goal pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "environment = envs[0] # Select the source environment\n",
    "\n",
    "plots = list()\n",
    "\n",
    "print('{}: {}'.format(environment, len(files[environment])))\n",
    "\n",
    "r = 0 # Select the starting index for the plotted trajectories\n",
    "for i,t in enumerate(files[environment][r:r+10]):\n",
    "\n",
    "    df = pd.read_csv(t)\n",
    "    \n",
    "    df['filtered_linear_x'] = df['linear_x'].rolling(window=7, center=True).mean().fillna(df['linear_x'])\n",
    "    df['filtered_angular_z'] = df['angular_z'].rolling(window=5, center=True).mean().fillna(df['angular_z'])\n",
    "    \n",
    "    distance = np.linalg.norm(df[['target_x', 'target_y']].values, axis=1)\n",
    "    \n",
    "    f1 = figure(title=t, plot_width=450, plot_height=300)\n",
    "    f1.line(df.index, df['linear_x'], line_color=Spectral6[0])\n",
    "    f1.line(df.index, df['filtered_linear_x'], line_color=Spectral6[5])\n",
    "    f1.line(df.index, distance, line_color=Spectral6[1])\n",
    "    \n",
    "    f2 = figure(plot_width=450, plot_height=300)\n",
    "    f2.line(df.index, df['angular_z'], line_color=Spectral6[0])\n",
    "    f2.line(df.index, df['filtered_angular_z'], line_color=Spectral6[5])\n",
    "    f2.line(df.index, df['target_yaw'], line_color=Spectral6[1])\n",
    "\n",
    "    plots.append([f1, f2])\n",
    "    \n",
    "show(gridplot(plots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generate final list of filtered trajectories\n",
    "\n",
    "We will drop 421 trajectories for various reasons, resulting in a set of 11602 trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_stats = stats.dropna().loc[(stats['samples'] > 10) & (stats['samples'] < 1000)].sort_values('samples')\n",
    "filtered_stats = filtered_stats.iloc[pca_include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the list of valid trajectories into a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'valid_trajectories.txt'), 'w') as f:\n",
    "    for t in filtered_stats['path'].values:\n",
    "        f.write(t + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a few stats about valid and invalid trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "excluded_stats = stats.iloc[~stats.index.isin(filtered_stats.index)]\n",
    "\n",
    "print('Valid trajectories: {}'.format(filtered_stats.shape[0]))\n",
    "print('Excluded trajectories: {}'.format(excluded_stats.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Valid samples: {}'.format(filtered_stats['samples'].sum()))\n",
    "print('Excluded samples: {}'.format(excluded_stats['samples'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the trajectories which belong to the evaluation set and print a few stats about them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.join(data_dir, 'evaluation')\n",
    "envs = os.listdir(base_dir)\n",
    "envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = dict()\n",
    "\n",
    "count = 0\n",
    "for f in envs:\n",
    "    path = os.path.join(base_dir, f)\n",
    "    files[f] = [os.path.join(path,x) for x in os.listdir(path)]\n",
    "    count += len(files[f])\n",
    "print('We have found {} files'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "for environment in envs:\n",
    "\n",
    "    print('{}: {} trajectories'.format(environment, len(files[environment])))\n",
    "\n",
    "    samples = 0\n",
    "    for i,t in enumerate(files[environment]):\n",
    "\n",
    "        df = pd.read_csv(t)\n",
    "        samples += df.shape[0]\n",
    "\n",
    "    print('{}: {} samples'.format(environment, samples))\n",
    "    total += samples\n",
    "    \n",
    "print('{}: {} samples'.format('Total', total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
